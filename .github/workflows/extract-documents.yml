name: Document Extraction Workflow with Embeddings

on:
  workflow_dispatch:
    inputs:
      input_directory:
        description: 'Input directory containing documents'
        required: false
        default: 'docs'
        type: string
      output_directory:
        description: 'Output directory for processed files'
        required: false
        default: 'build'
        type: string
      enable_embeddings:
        description: 'Enable document chunking and embedding'
        required: false
        default: false
        type: boolean
      embedding_model:
        description: 'OpenAI embedding model'
        required: false
        default: 'text-embedding-3-small'
        type: choice
        options:
          - 'text-embedding-3-small'
          - 'text-embedding-3-large'
          - 'text-embedding-ada-002'
      vector_db:
        description: 'Vector database type'
        required: false
        default: 'chromadb'
        type: choice
        options:
          - 'chromadb'
          - 'faiss'
      chunk_size:
        description: 'Text chunk size for embedding'
        required: false
        default: '1000'
        type: string
      chunk_overlap:
        description: 'Overlap between chunks'
        required: false
        default: '200'
        type: string
      search_query:
        description: 'Test search query (requires embeddings)'
        required: false
        default: ''
        type: string
      verbose:
        description: 'Enable verbose logging'
        required: false
        default: false
        type: boolean

jobs:
  extract-documents:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ghostscript
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Verify OpenAI API key
      if: inputs.enable_embeddings == true
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        if [ -z "$OPENAI_API_KEY" ]; then
          echo "âŒ ERROR: OPENAI_API_KEY secret is required for embeddings!"
          echo "Please add your OpenAI API key as a repository secret."
          exit 1
        else
          echo "âœ… OpenAI API key is configured"
        fi
        
    - name: Create input directory if it doesn't exist
      run: |
        mkdir -p ${{ inputs.input_directory || 'docs' }}
        
    - name: Check for documents
      run: |
        echo "=== ğŸ“ Checking for input documents ==="
        INPUT_DIR="${{ inputs.input_directory || 'docs' }}"
        
        PDF_COUNT=$(find "$INPUT_DIR" -name "*.pdf" -type f 2>/dev/null | wc -l || echo "0")
        XLSX_COUNT=$(find "$INPUT_DIR" -name "*.xlsx" -type f 2>/dev/null | wc -l || echo "0")
        CSV_COUNT=$(find "$INPUT_DIR" -name "*.csv" -type f 2>/dev/null | wc -l || echo "0")
        
        echo "ğŸ“„ PDF files: $PDF_COUNT"
        echo "ğŸ“Š Excel files: $XLSX_COUNT"
        echo "ğŸ“‹ CSV files: $CSV_COUNT"
        
        if [ "$PDF_COUNT" -eq 0 ] && [ "$XLSX_COUNT" -eq 0 ] && [ "$CSV_COUNT" -eq 0 ]; then
          echo "âš ï¸  No documents found in $INPUT_DIR"
          echo "Please add PDF, Excel, or CSV files to process."
        else
          echo "âœ… Found $((PDF_COUNT + XLSX_COUNT + CSV_COUNT)) documents to process"
          find "$INPUT_DIR" -type f \( -name "*.pdf" -o -name "*.xlsx" -o -name "*.csv" \) -exec ls -lh {} \;
        fi
        
    - name: Run document extraction
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        # Build command with inputs
        CMD="python extract_docs.py"
        CMD="$CMD --input '${{ inputs.input_directory || 'docs' }}'"
        CMD="$CMD --output '${{ inputs.output_directory || 'build' }}'"
        
        if [ "${{ inputs.verbose }}" = "true" ]; then
          CMD="$CMD --verbose"
        fi
        
        if [ "${{ inputs.enable_embeddings }}" = "true" ]; then
          CMD="$CMD --embed"
          CMD="$CMD --embedding-model '${{ inputs.embedding_model || 'text-embedding-3-small' }}'"
          CMD="$CMD --vector-db '${{ inputs.vector_db || 'chromadb' }}'"
          CMD="$CMD --chunk-size '${{ inputs.chunk_size || '1000' }}'"
          CMD="$CMD --chunk-overlap '${{ inputs.chunk_overlap || '200' }}'"
          
          if [ -n "${{ inputs.search_query }}" ]; then
            CMD="$CMD --search '${{ inputs.search_query }}'"
          fi
        fi
        
        echo "ğŸš€ Running: $CMD"
        eval $CMD
        
    - name: Display category organization
      run: |
        echo "=== ğŸ“‚ CATEGORY-BASED ORGANIZATION ==="
        OUTPUT_DIR="${{ inputs.output_directory || 'build' }}"
        
        echo ""
        echo "ğŸ“ Markdown Files by Category:"
        for category in financial legal transcript other; do
          if [ -d "$OUTPUT_DIR/md/$category" ]; then
            count=$(find "$OUTPUT_DIR/md/$category" -name "*.md" -type f 2>/dev/null | wc -l || echo "0")
            if [ "$count" -gt 0 ]; then
              echo "  ğŸ“ $category/: $count files"
              find "$OUTPUT_DIR/md/$category" -name "*.md" -type f | head -3 | sed 's/^/    ğŸ“„ /'
            fi
          fi
        done
        
        echo ""
        echo "ğŸ“Š CSV Files by Category:"
        for category in financial legal transcript other; do
          if [ -d "$OUTPUT_DIR/csv/$category" ]; then
            count=$(find "$OUTPUT_DIR/csv/$category" -name "*.csv" -type f 2>/dev/null | wc -l || echo "0")
            if [ "$count" -gt 0 ]; then
              echo "  ğŸ“ $category/: $count files"
              find "$OUTPUT_DIR/csv/$category" -name "*.csv" -type f | head -3 | sed 's/^/    ğŸ“Š /'
            fi
          fi
        done
        
    - name: Show vector database info
      if: inputs.enable_embeddings == true
      run: |
        OUTPUT_DIR="${{ inputs.output_directory || 'build' }}"
        echo "=== ğŸ§  VECTOR DATABASE INFO ==="
        
        if [ -d "$OUTPUT_DIR/vectors" ]; then
          echo "ğŸ“ Vector database files:"
          ls -la "$OUTPUT_DIR/vectors/" | sed 's/^/  /'
          
          echo ""
          echo "ğŸ’¾ Vector database size:"
          du -sh "$OUTPUT_DIR/vectors/"* 2>/dev/null | sed 's/^/  /' || echo "  No vector files found"
        else
          echo "âš ï¸  No vector database directory found"
        fi
        
    - name: Show index.json summary
      run: |
        OUTPUT_DIR="${{ inputs.output_directory || 'build' }}"
        if [ -f "$OUTPUT_DIR/index.json" ]; then
          echo "=== ğŸ“‡ INDEX.JSON SUMMARY ==="
          
          # Count entries by category
          echo "ğŸ“Š Documents by category:"
          for category in financial legal transcript other; do
            count=$(jq -r "to_entries[] | select(.value.category == \"$category\") | .key" "$OUTPUT_DIR/index.json" 2>/dev/null | wc -l || echo "0")
            if [ "$count" -gt 0 ]; then
              echo "  ğŸ“ $category: $count documents"
            fi
          done
          
          total_docs=$(jq 'length' "$OUTPUT_DIR/index.json" 2>/dev/null || echo "0")
          echo "  ğŸ“‹ Total documents: $total_docs"
        fi
        
    - name: Upload category-organized results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: document-extraction-results
        path: |
          ${{ inputs.output_directory || 'build' }}/md/
          ${{ inputs.output_directory || 'build' }}/csv/
          ${{ inputs.output_directory || 'build' }}/index.json
        retention-days: 30
        
    - name: Upload vector database
      uses: actions/upload-artifact@v4
      if: inputs.enable_embeddings == true
      with:
        name: vector-database
        path: |
          ${{ inputs.output_directory || 'build' }}/vectors/
        retention-days: 30
        
    - name: Upload processing logs
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: extraction-logs
        path: |
          ${{ inputs.output_directory || 'build' }}/logs/
        retention-days: 7
        
    - name: Final summary
      if: always()
      run: |
        OUTPUT_DIR="${{ inputs.output_directory || 'build' }}"
        echo "=== ğŸ‰ EXTRACTION COMPLETE ==="
        echo ""
        echo "âš™ï¸  Configuration:"
        echo "  ğŸ“ Input: ${{ inputs.input_directory || 'docs' }}"
        echo "  ğŸ“¤ Output: $OUTPUT_DIR"
        echo "  ğŸ” Verbose: ${{ inputs.verbose || 'false' }}"
        echo "  ğŸ§  Embeddings: ${{ inputs.enable_embeddings || 'false' }}"
        
        if [ "${{ inputs.enable_embeddings }}" = "true" ]; then
          echo "  ğŸ¤– Model: ${{ inputs.embedding_model || 'text-embedding-3-small' }}"
          echo "  ğŸ—ƒï¸  Vector DB: ${{ inputs.vector_db || 'chromadb' }}"
          echo "  ğŸ“ Chunk size: ${{ inputs.chunk_size || '1000' }}"
          echo "  ğŸ”— Overlap: ${{ inputs.chunk_overlap || '200' }}"
        fi
        
        echo ""
        echo "ğŸ“Š Results by Category:"
        TOTAL_MD=0
        TOTAL_CSV=0
        
        for category in financial legal transcript other; do
          if [ -d "$OUTPUT_DIR/md/$category" ] || [ -d "$OUTPUT_DIR/csv/$category" ]; then
            md_count=$(find "$OUTPUT_DIR/md/$category" -name "*.md" -type f 2>/dev/null | wc -l || echo "0")
            csv_count=$(find "$OUTPUT_DIR/csv/$category" -name "*.csv" -type f 2>/dev/null | wc -l || echo "0")
            
            if [ "$md_count" -gt 0 ] || [ "$csv_count" -gt 0 ]; then
              echo "  ğŸ“‚ $category: $md_count MD, $csv_count CSV"
              TOTAL_MD=$((TOTAL_MD + md_count))
              TOTAL_CSV=$((TOTAL_CSV + csv_count))
            fi
          fi
        done
        
        LOG_COUNT=$(find "$OUTPUT_DIR/logs" -name "*.log" -type f 2>/dev/null | wc -l || echo "0")
        
        echo ""
        echo "ğŸ¯ Totals:"
        echo "  ğŸ“ Markdown files: $TOTAL_MD"
        echo "  ğŸ“Š CSV files: $TOTAL_CSV"
        echo "  ğŸ“‹ Log files: $LOG_COUNT"
        
        if [ -f "$OUTPUT_DIR/index.json" ]; then
          index_entries=$(jq 'length' "$OUTPUT_DIR/index.json" 2>/dev/null || echo "0")
          echo "  ğŸ“‡ Indexed documents: $index_entries"
        fi
        
        echo ""
        echo "ğŸ“¦ Artifacts:"
        echo "  ğŸ“ document-extraction-results (MD, CSV, index.json)"
        if [ "${{ inputs.enable_embeddings }}" = "true" ]; then
          echo "  ğŸ§  vector-database (ChromaDB/FAISS files)"
        fi
        echo "  ğŸ“‹ extraction-logs (processing logs)"
        
        echo ""
        echo "âœ… Processing complete! Download artifacts above."
